{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwBCE43Cv3PH"
   },
   "source": [
    "# Pandas Dataframe oefening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQB7yiF6v9GR"
   },
   "source": [
    "# Inladen van een pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmyEaf4Awl2v"
   },
   "source": [
    "Maak gebruik van een kleine <a href=\"https://archive.ics.uci.edu/ml/datasets/heart+Disease\" class=\"external\">dataset</a> over hartziektes dat beschikbaar gesteld wordt door de UCI Machine Learning Repository.\n",
    "Deze dataset is een csv bestaande uit een aantal honderd lijnen.\n",
    "Elke lijn beschrijft een patient en elke kolom een kenmerk van de patient.\n",
    "We gaan in deze notebook proberen te voorspelen of een patient een hartziekte heeft op basis van deze gegevens.\n",
    "Dit is een binaire classificatie taak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iiyC7HkqxlUD"
   },
   "source": [
    "## Inlezen van de data via pandas\n",
    "\n",
    "Schrijf in de code cell hieronder de nodige code om met behulp van pandas (zoals we bij datascience gezien hebben) de dataset te downloaden en in te lezen via pandas.\n",
    "De link naar de dataset zelf is https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/.\n",
    "Print daarna de eerste 10 rijen uit van de dataset en de datatypes van elke kolom.\n",
    "Splits ten slotte de dataset in twee delen, namelijk de features en de labels/targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendatasets as od\n",
    "import pandas as pd\n",
    "\n",
    "od.download(\"https://storage.googleapis.com/download.tensorflow.org/data/heart.csv\")\n",
    "\n",
    "df = pd.read_csv(\"heart.csv\")\n",
    "display(df.head(10))\n",
    "display(df.dtypes)\n",
    "\n",
    "features = df.loc[:, df.columns != \"target\"]\n",
    "display(features.head())\n",
    "targets = df[\"target\"]\n",
    "display(targets.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model trainen met minimale preprocessing\n",
    "\n",
    "Op basis van deze dataset kan je nu een model trainen.\n",
    "Bij Data Science hebben we hiervoor gebruik gemaakt van de sklearn library.\n",
    "\n",
    "Maak voor het model te trainen een pipeline aan.\n",
    "Voer in deze pipeline de volgende preprocessing stappen uit.\n",
    "* Voer normalisatie uit op de numerieke kolommen ('age', 'thalach', 'trestbps',  'chol', 'oldpeak')\n",
    "\n",
    "Na het uitvoeren van de preprocessing stappen, train een Random Forest Classifier met zelfgekozen hyperparameters.\n",
    "Welke accuraatheid behaal je met een test-size van 20%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "num_cols = ['age', 'thalach', 'trestbps', 'chol', 'oldpeak']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, targets, test_size = 0.2)\n",
    "\n",
    "#  pipeline\n",
    "p = Pipeline(steps = [\n",
    "    (\"preprocessor\", ColumnTransformer(transformers=[\n",
    "        ('num_imputer', StandardScaler(), num_cols)\n",
    "    ])),\n",
    "    (\"rf\", RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Preprocessing\n",
    "p.fit(X_train, y_train)\n",
    "p.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test[num_cols], y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model trainen met volledige preprocessing\n",
    "\n",
    "Maak voor het model te trainen een pipeline aan.\n",
    "Voer in deze pipeline de volgende preprocessing stappen uit.\n",
    "* Voer normalisatie uit op de numerieke kolommen ('age', 'thalach', 'trestbps',  'chol', 'oldpeak')\n",
    "* Voer one-hot encoding uit op de categorieke kolommen\n",
    "\n",
    "Na het uitvoeren van de preprocessing stappen, train een Random Forest Classifier met zelfgekozen hyperparameters.\n",
    "Welke accuraatheid behaal je met een test-size van 20%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "num_cols = ['age', 'thalach', 'trestbps', 'chol', 'oldpeak']\n",
    "cat_cols = list(set(df.columns) - set(num_cols))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, targets, test_size = 0.2)\n",
    "\n",
    "#  pipeline\n",
    "p = Pipeline(steps = [\n",
    "    (\"preprocessor\", ColumnTransformer(transformers=[\n",
    "        ('num_imputer', StandardScaler(), num_cols),\n",
    "        ('ohe_encoder', OneHotEncoder(), cat_cols)\n",
    "    ])),\n",
    "    (\"rf\", RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Preprocessing\n",
    "p.fit(X_train, y_train)\n",
    "p.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pandas_dataframe.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
