{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment of neural networks\n",
    "\n",
    "In de vorige weken heb je geleerd hoe je neurale netwerken kan aanmaken, trainen en evalueren.\n",
    "Wanneer je een goed werkend model hebt wil je dit vaak in de praktijk gebruiken/ in productie brengen.\n",
    "Deze stap wordt typisch deployment van een model genoemd. \n",
    "\n",
    "Er zijn verscheidene manieren om een model te deployen:\n",
    "* Remote\n",
    "* On-Device\n",
    "\n",
    "## Remote access\n",
    "\n",
    "Een eerste manier om een model te gebruiken in een applicatie is door het model op een server te plaatsen.\n",
    "Dit kan op door onder andere gebruik te maken van een bestaande cloud-service (Azure, AWS, Firebase, ...) of op een eigen server te plaatsen.\n",
    "In beide gevallen wordt er dan een request gestuurd naar de server gestuurd met de input voor het model.\n",
    "De server voert dan het model uit en met de gegeven input en stuurt het antwoord terug.\n",
    "\n",
    "Deze techniek wordt vaak gebruikt voor complexe modellen die te zwaar zouden zijn om uit te voeren op de meeste devices waarvoor het bedoeld is (robots/smartphones/...).\n",
    "Ook is je model beschermd tegen misbruik omdat de verschillende gebruikers geen toegang hebben tot de structuur van het model en de gewichten.\n",
    "Hierdoor kan je gemakkelijker het aantal voorspellingen controleren van een gebruiker en hiervoor de nodige kosten aanrekenen.\n",
    "\n",
    "Echter zijn er ook nadelen verbonden met deze techniek. Het grootste nadeel is dat er steeds een netwerkverbinding moet zijn voor het model te laten werken.\n",
    "Hierdoor is het niet altijd bruikbaar om een remote model te gebruiken.\n",
    "Door de netwerk communicatie kan het ook langer duren voor een voorspelling uitgevoerd is (vooral voor kleinere modellen).\n",
    "\n",
    "## On-Device\n",
    "\n",
    "Door de opkomst van neurale netwerken in allerhande toepassingen is er ook een nood aan de netwerken te gebruiken in verschillende talen.\n",
    "Tensorflow is geschreven in de programmeertaal C om performantieredenen en kan daardoor eenvoudig gebruikt worden allerhande packages.\n",
    "Hierdoor zijn er allerlei packages/libraries ontwikkeld in allerhande talen om met ML aan de slag te gaan.\n",
    "Zo is er:\n",
    "* Tensorflow.net in C#\n",
    "* Een interface om tensorflow code aan te spreken met Java\n",
    "* Tensorflow lite voor bvb kotlin om op android te developpen\n",
    "\n",
    "De voordelen bij het gebruiken van een on-device toepassing is dat je steeds gebruik kunt maken van het model, ook zonder netwerk verbinding.\n",
    "Dit kan belangrijk zijn bij real-time applicaties.\n",
    "Het belangrijkste nadeel is dat de complexiteit van het model beperkt is door de beperkingen van het (zwakste) toestel waarop de applicatie moet werken.\n",
    "\n",
    "## Firebase\n",
    "\n",
    "Een cloud-service die onder andere gebruikt kan worden als NoSQL database voor je applicaties.\n",
    "Ook kan firebase gebruikt worden voor de volgende zaken:\n",
    "* Bijhouden van je modellen\n",
    "* Mogelijkheid om updates van je model te verspreiden naar alle devices die er nood aan hebben\n",
    "* Bijhouden van logs om verdere training/optimalisatie uit te voeren\n",
    "* Uitvoeren van voorspellingen\n",
    "\n",
    "Volg eerst de stappen op [deze pagina](https://firebase.google.com/docs/ml/manage-hosted-models) om een firebase project aan te maken via de Firebase Admin SDK dat we gaan gebruiken in de loop van deze notebook.\n",
    "\n",
    "In de code hieronder gaan we werken met een bestaand ML-model dat bewaard is in de **model.keras file**.\n",
    "Dit model is getrained op de MNIST dataset om handgeschreven cijfers te herkennen)\n",
    "Dit tensorflow model gaan we daarna omzetten naar een tensorflow-lite model (dit is het type waarmee firebase werkt en is een lightweight versie van het tensorflow model).\n",
    "Dit tensorflowlite model kan geupload worden naar firestore. \n",
    "Volg hiervoor de tutorial verder om het model te plaatsen op de firestore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install firebase_admin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<firebase_admin.App at 0x2ee7a5a5cf0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connect to firebase\n",
    "import firebase_admin\n",
    "from firebase_admin import ml\n",
    "from firebase_admin import credentials\n",
    "import tensorflow as tf\n",
    "\n",
    "firebase_admin.initialize_app(\n",
    "    credentials.Certificate(\"../../../../firebase_admin.json\"),\n",
    "    options={\n",
    "        'storageBucket': 'ml-deployment-707dd.appspot.com'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download model and create new model\n",
    "\n",
    "model =tf.keras.models.load_model('model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\JENS~1.BAE\\AppData\\Local\\Temp\\tmpwr4i6c2l\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\JENS~1.BAE\\AppData\\Local\\Temp\\tmpwr4i6c2l\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<firebase_admin.ml.Model at 0x2ee74cc72b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = ml.TFLiteGCSModelSource.from_keras_model(model)\n",
    "\n",
    "tflite_model = ml.TFLiteFormat(tmp)\n",
    "model = ml.Model(\n",
    "    display_name=\"Voorbeeld\",\n",
    "    tags=[\"Voorbeeld\", \"uit\", \"les\"],\n",
    "    model_format=tflite_model\n",
    ")\n",
    "\n",
    "firebase_model = ml.create_model(model)\n",
    "ml.publish_model(firebase_model.model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onder de Machine Learning pagina op je project pagina van Firebase kan je verifieren of het uploaden van het model geslaagd is.\n",
    "Indien je de informatie van het model later wil aanpassen of updaten kan je dat doen op de volgende manier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<firebase_admin.ml.Model at 0x2ee64262950>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add tags to the model\n",
    "firebase_model.display_name = \"Voorbeeld2\"\n",
    "\n",
    "updated_model = ml.update_model(firebase_model)\n",
    "ml.publish_model(updated_model.model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu kan dit model door je applicatie gedownload worden en het model gebruikt worden om voorspellingen te doen.\n",
    "Schrijf in de cell hieronder de nodige code om dit uit te voeren en maak gebruik van de figuur **test.png** om te kijken of het model correct werkt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'projects/ml-deployment-707dd/models/20030888', 'displayName': 'Voorbeeld2', 'createTime': '2022-10-25T12:28:31.102905Z', 'updateTime': '2022-10-25T12:29:39.546239Z', 'state': {'published': True}, 'etag': '9062183a118e6fa6f5a3d5bed19f387d46565f9c36fd41c94ddaa56f4640e1ff', 'modelHash': '37c5c97709e5681490b56a250416e01065b9016c474a7b3464bb731d12909f0e', 'tags': ['Voorbeeld', 'les', 'uit'], 'tfliteModel': {'sizeBytes': '408808', 'gcsTfliteUri': 'gs://ml-deployment-707dd.appspot.com/Firebase/ML/Models/firebase_ml_model.tflite'}}\n",
      "20030888\n"
     ]
    }
   ],
   "source": [
    "# use the model\n",
    "\n",
    "iterator = ml.list_models().iterate_all()\n",
    "for m  in iterator:\n",
    "    fields = m.as_dict()\n",
    "    print(fields)\n",
    "\n",
    "    model_id = fields[\"name\"].split(\"/\")[-1]\n",
    "    print(model_id)\n",
    "\n",
    "    filepath = fields[\"tfliteModel\"][\"gcsTfliteUri\"].split(\"appspot.com/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buiten het model te downloaden en te gebruiken als een on-device model is het ook mogelijk om dit model uit te voeren in de cloud.\n",
    "Dit kan je doen door een Get-request te sturen naar Firebase met de input.\n",
    "Als response krijg je dan de output.\n",
    "Echter moet hiervoor je account een upgrade hebben naar een betalende account.\n",
    "Dit zou nog steeds gratis moeten zijn indien je binnen de grenzen blijft van het gratis plan maar indien er toch iets misgaat of je verkeerd doet gaan we dit niet doen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure\n",
    "\n",
    "Natuurlijk is Firebase slechts 1 van de mogeljke cloud-services om te gebruiken.\n",
    "Een andere mogelijkheid is om gebruik te maken van de **Azure** cloud omgeving.\n",
    "Een tutorial bestaande uit 2 delen kan je hier vinden:\n",
    "* [Deel 1](https://medium.com/@mostafa.m.ayoub/deploy-your-local-python-ml-project-to-azure-part-1-b8a98b6e574a): Opzetten van de omgeving\n",
    "* [Deel 2](https://medium.com/@mostafa.m.ayoub/deploy-your-local-python-ml-project-to-azure-part-2-392ac4dbdd75): Deploy local ML to Azure\n",
    "\n",
    "Eerst moeten we nog de nodige software installeren om python te kunnen gebruiken samen met azure:\n",
    "* Installeren Acure CLI, zie [hier](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-cli?tabs=public)\n",
    "* Installeren Azure ML SDK: v1 is tot python 3.9 ([link](https://docs.microsoft.com/en-us/python/api/overview/azure/ml/install?view=azure-ml-py)) of v2 voor nieuwere python versies ([link](https://docs.microsoft.com/en-us/python/api/overview/azure/ml/installv2?view=azure-ml-py))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5e8e3a19af5ceb2434683dff87da6345c3b29f7eb0a8a138558c07d014a01cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
