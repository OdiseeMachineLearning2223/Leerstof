{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer vision problems\n",
    "\n",
    "Vorige week heb je geleerd hoe je gebruik kan maken van convolutionele lagen om op een efficiente manier classificatie problemen uit te voeren op beelden.\n",
    "Echter zijn er naast classificatie problemen ook andere zaken die je kan doen in het domein van computer visie.\n",
    "\n",
    "De meest voorkomende hiervan zijn:\n",
    "* Object Localization\n",
    "* Object Detection \n",
    "* Image Segmentation\n",
    "\n",
    "Modellen voor deze oplossingen kunnen zelf gemaakt worden (een oefening hierop gaan we uitvoeren bij image segmentation).\n",
    "Echter zijn ze vaak heel complex waardoor het vaak eenvoudiger en sneller is om bestaande oplossingen/modellen hiervoor te gebruiken.\n",
    "Gelukkig zijn er hiervoor een hele reeks te vinden op tensorflow hub.\n",
    "\n",
    "## Object Localization\n",
    "\n",
    "Hierbij wordt de regio aangeduid van elke klasse waarin een object gezien wordt.\n",
    "Dit houdt echter in dat er slechts maar 1 object van elke klasse kan gedetecteerd worden.\n",
    "\n",
    "Dit kan eenvoudig gedaan worden door het classificatieprobleem aan te passen waarbij je ipv 1 neuron te gebruiken er 4 gebruikt (of 5).\n",
    "Deze 4 of 5 neurons kunnen dan bijvoorbeeld staan voor:\n",
    "* xmin van de bounding box\n",
    "* ymin van de bounding box\n",
    "* width van de bouding box\n",
    "* height van de bouding box\n",
    "* optionele zekerheid van de classe/bounding box\n",
    "\n",
    "## Object Detection\n",
    "\n",
    "Object detectie is een uitbreiding van object localization waarbij geprobeerd wordt alle objecten in een figuur te detecteren en classificeren.\n",
    "Er zijn doorheen de jaren een hele reeks neurale netwerken getrained voor verschillende inputs/classes/snelheden/... \n",
    "Een overzicht hiervan kan je vinden op [deze link](https://tfhub.dev/tensorflow/collections/object_detection/1)\n",
    "\n",
    "**Oefening**\n",
    "\n",
    "Voer de volgende stappen uit:\n",
    "* Kies een model uit de lijst van tensorflow hub\n",
    "* Bekijk de colab notebook en bestudeer de code uit de verschillende cellen\n",
    "* Haal er de minimum code uit om het neuraal netwerk te downloaden en te gebruiken\n",
    "* Kies een figuur op het internet en voer er object detectie op uit met je zelfgekozen neuraal netwerk\n",
    "* Maak een plot van de input figuur met de gedetecteerde objecten erop getekend. Let op bij het weergeven van de namen van de classen. Dit lukt niet altijd zoals in de notebook op tensorflow. (Tip: kijk naar de notebook op tensorflow en de democode uit lesweek 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "\n",
    "with open('ImageNetLabels.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "    for line in lines:\n",
    "        labels.append(line.replace(\"\\n\", \"\"))\n",
    "\n",
    "labels = ['person','bicycle','car','motorcycle','airplane','bus','train','truck','boat','traffic light','fire hydrant','stop sign','parking meter','bench','bird','cat','dog','horse','sheep','cow','elephant','bear','zebra','giraffe','backpack','umbrella','handbag','tie','suitcase','frisbee','skis','snowboard','sports ball','kite','baseball bat','baseball glove','skateboard','surfboard','tennis racket','bottle','wine glass','cup','fork','knife','spoon','bowl','banana','apple','sandwich','orange','broccoli','carrot','hot dog','pizza','donut','cake','chair','couch','potted plant','bed','dining table','toilet','tv','laptop','mouse','remote','keyboard','cell phone','microwave','oven','toaster','sink','refrigerator','book','clock','vase','scissors','teddy bear','hair drier','toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an object detection model from tensorflow hub\n",
    "# load the same image as in the previous example\n",
    "# make the prediction for the image\n",
    "# show image and predicted objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image segmentation\n",
    "\n",
    "Een uitbreiding op object detectie is dat we gaan kijken voor elke pixel of groep pixels tot welke klasse het behoort.\n",
    "Ook hiervoor bestaan er een reeks bestaande netwerken op tensorflow hub, zie [deze link](https://tfhub.dev/s?module-type=image-segmentation).\n",
    "\n",
    "Let op dat het Mask R-CNN model hier niet tussen staat omdat het technisch gezien object detectie doet maar de resultaten kunnen ook gebruikt worden voor image segmentation.\n",
    "Bekijk de notebook voor object detection met mask r-cnn en voer image segmentation uit met dezelfde figuur.\n",
    "\n",
    "Let op dat ik bij het voorbereiden door een versieverschil een fout kreeg met de standaard reframe_box_masks_to_image_masks functie.\n",
    "Indien je hier ook een fout mee krijgt kan je de onderstaande functie gebruiken. (Aanpassing staat in commentaar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy from package and fixed?\n",
    "def reframe_box_masks_to_image_masks(box_masks, boxes, image_height,\n",
    "                                     image_width):\n",
    "  \"\"\"Transforms the box masks back to full image masks.\n",
    "\n",
    "  Embeds masks in bounding boxes of larger masks whose shapes correspond to\n",
    "  image shape.\n",
    "\n",
    "  Args:\n",
    "    box_masks: A tf.float32 tensor of size [num_masks, mask_height, mask_width].\n",
    "    boxes: A tf.float32 tensor of size [num_masks, 4] containing the box\n",
    "           corners. Row i contains [ymin, xmin, ymax, xmax] of the box\n",
    "           corresponding to mask i. Note that the box corners are in\n",
    "           normalized coordinates.\n",
    "    image_height: Image height. The output mask will have the same height as\n",
    "                  the image height.\n",
    "    image_width: Image width. The output mask will have the same width as the\n",
    "                 image width.\n",
    "\n",
    "  Returns:\n",
    "    A tf.float32 tensor of size [num_masks, image_height, image_width].\n",
    "  \"\"\"\n",
    "  # TODO(rathodv): Make this a public function.\n",
    "  def reframe_box_masks_to_image_masks_default():\n",
    "    \"\"\"The default function when there are more than 0 box masks.\"\"\"\n",
    "    def transform_boxes_relative_to_boxes(boxes, reference_boxes):\n",
    "      boxes = tf.reshape(boxes, [-1, 2, 2])\n",
    "      min_corner = tf.expand_dims(reference_boxes[:, 0:2], 1)\n",
    "      max_corner = tf.expand_dims(reference_boxes[:, 2:4], 1)\n",
    "      transformed_boxes = (boxes - min_corner) / (max_corner - min_corner)\n",
    "      return tf.reshape(transformed_boxes, [-1, 4])\n",
    "\n",
    "    box_masks_expanded = tf.expand_dims(box_masks, axis=3)\n",
    "    num_boxes = tf.shape(box_masks_expanded)[0]\n",
    "    unit_boxes = tf.concat(\n",
    "        [tf.zeros([num_boxes, 2]), tf.ones([num_boxes, 2])], axis=1)\n",
    "    reverse_boxes = transform_boxes_relative_to_boxes(unit_boxes, boxes)\n",
    "    return tf.image.crop_and_resize(\n",
    "        image=box_masks_expanded,\n",
    "        boxes=reverse_boxes,\n",
    "        box_indices=tf.range(num_boxes),    # dit heb ik aangepast (stond oorspronkelijk box_ind)\n",
    "        crop_size=[image_height, image_width],\n",
    "        extrapolation_value=0.0)\n",
    "  image_masks = tf.cond(\n",
    "      tf.shape(box_masks)[0] > 0,\n",
    "      reframe_box_masks_to_image_masks_default,\n",
    "      lambda: tf.zeros([0, image_height, image_width, 1], dtype=tf.float32))\n",
    "  return tf.squeeze(image_masks, axis=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image segmentation model from tensorflow hub\n",
    "# load the same image as in the previous example\n",
    "# make the prediction for the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show original image and its mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natuurlijk is het ook mogelijk om dit soort netwerken zelf te maken. \n",
    "Als experiment gaan we op beelden de soort en ras van huisdieren gaan bepalen.\n",
    "Hiervoor gaan we gebruik maken van [deze dataset](https://www.kaggle.com/datasets/devdgohil/the-oxfordiiit-pet-dataset).\n",
    "\n",
    "Download in de cell hieronder de dataset en bekijk de files die gedownload zijn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendatasets as od\n",
    "od.download(\"https://www.kaggle.com/datasets/devdgohil/the-oxfordiiit-pet-dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Er zijn twee folders gedownload. \n",
    "De folder images bevat alle figuren in de dataset waarbij de naam van de file begint met de klasse waartoe het behoort.\n",
    "De folder annotations is iets complexer en bevat segmentation masks voor elke figuur in de trimaps folder en extra metadata voor elke figuur in de xmls file.\n",
    "Deze metadata bevat bijvoorbeeld informatie over de bounding boxes van de dieren in de figuren.\n",
    "In dit deel gaan we enkel werken met de informatie uit de trimaps folder om het model te trainen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"the-oxfordiiit-pet-dataset/images/images\"\n",
    "target_dir = \"the-oxfordiiit-pet-dataset/annotations/annotations/trimaps\"\n",
    "\n",
    "import os\n",
    "input_img_paths = sorted([os.path.join(input_dir,fname) for fname in os.listdir(input_dir) if fname.endswith(\".jpg\")])\n",
    "target_paths = sorted([os.path.join(target_dir,fname) for fname in os.listdir(target_dir) if fname.endswith(\".png\") and not fname.startswith(\".\")])\n",
    "\n",
    "print(\"Num inputs: \", len(input_img_paths))\n",
    "print(\"Num targets: \", len(target_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show some input images (2 rows of 8 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show some target images (2 rows of 8 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the figures have different sizes => make everything 200x200\n",
    "\n",
    "# set some images aside for validation\n",
    "\n",
    "# maak een Data Sequence Generator voor train en validatie data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build and make model\n",
    "\n",
    "# print summary - how many parameters do you have?\n",
    "\n",
    "# compile the model and pick an optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add call back for saving best model\n",
    "\n",
    "# train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a random target image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model (saved by checkpoints) instead of model resulting from final fit\n",
    "\n",
    "# display mask over the random target image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d5e8e3a19af5ceb2434683dff87da6345c3b29f7eb0a8a138558c07d014a01cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
